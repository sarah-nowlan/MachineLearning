{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["Python script to scrape an article given the url of the article and store the extracted text in a file<br>\n", "Url: https://medium.com/@subashgandyer/papa-what-is-a-neural-network-c5e5cc427c7"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import os\n", "import requests\n", "import re"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Code here - Import BeautifulSoup library "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from bs4 import BeautifulSoup\n", "# Code ends here"]}, {"cell_type": "markdown", "metadata": {}, "source": ["function to get the html source text of the medium article"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def get_page():\n", "\tglobal url\n", "\t\n", "\t# Code here - Ask the user to input \"Enter url of a medium article: \" and collect it in url \n", "\turl = input(\"Enter url of a medium article: \")\n", "\t# Code ends here\n", "\t\n", "\t# handling possible error\n", "\tif not re.match(r'https?://medium.com/',url):\n", "\t\tprint('Please enter a valid website, or make sure it is a medium article')\n", "\t\tsys.exit(1)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["\t# Code here - Call get method in requests object, pass url and collect it in res\n", "\tres = requests.get(url)\n", "\t# Code ends here"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["\tres.raise_for_status()\n", "\tsoup = BeautifulSoup(res.text, 'html.parser')\n", "\treturn soup"]}, {"cell_type": "markdown", "metadata": {}, "source": ["function to remove all the html tags and replace some with specific strings"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def clean(text):\n", "    rep = {\"<br>\": \"\\n\", \"<br/>\": \"\\n\", \"<li>\":  \"\\n\"}\n", "    rep = dict((re.escape(k), v) for k, v in rep.items()) \n", "    pattern = re.compile(\"|\".join(rep.keys()))\n", "    text = pattern.sub(lambda m: rep[re.escape(m.group(0))], text)\n", "    text = re.sub('\\<(.*?)\\>', '', text)\n", "    return text"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def collect_text(soup):\n", "\ttext = f'url: {url}\\n\\n'\n", "\tpara_text = soup.find_all('p')\n", "\tprint(f\"paragraphs text = \\n {para_text}\")\n", "\tfor para in para_text:\n", "\t\ttext += f\"{para.text}\\n\\n\"\n", "\treturn text"]}, {"cell_type": "markdown", "metadata": {}, "source": ["function to save file in the current directory"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def save_file(text):\n", "\tif not os.path.exists('./scraped_articles'):\n", "\t\tos.mkdir('./scraped_articles')\n", "\tname = url.split(\"/\")[-1]\n", "\tprint(name)\n", "\tfname = f'scraped_articles/{name}.txt'\n", "\t\n", "\t# Code here - write a file using with (2 lines)\n", "\twith open(fname, \"w\") as f:\n", "\t\tf.write(text) \n", "\t# Code ends here"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["\tprint(f'File saved in directory {fname}')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["if __name__ == '__main__':\n", "\ttext = collect_text(get_page())\n", "\tsave_file(text)\n", "\t# Instructions to Run this python code\n", "\t# Give url as https://medium.com/@subashgandyer/papa-what-is-a-neural-network-c5e5cc427c7"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}